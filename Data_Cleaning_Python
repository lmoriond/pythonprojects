######### Data_Cleaning_Python

--------------------------------------------------### Missing values in a column

import pandas as pd

df = pd.read_csv(
      'cart.csv',
       parse_dates=['dates'])
df

         ## see the data types (datetime64, object, float64, etc)
df.dtypes

         ## we set 'amount' to a numeric value data type (previusly a float64)
df ['amount'].astype('Int32')

         ## see if we have isnull with pandas (true/false for every value)
df.isnull()

         ## is null for each row only
df.isnull().any(axis=1)

--------------------------------------------------### Bad values in raw data

import pandas as pd

df = pd.read_csv(
      'metrics.csv',
       parse_dates=['time'])
df.sample(10)

         ## we group by to see typo errors like mayusc(select disctint) 
df.groupby('name').describe()

         ## we can count the variables to see which one we use
df.['name'].value_counts()

         ## we make a pivot to visualize the ranges and names
pd.pivot(df, index='time', columns='name').plot(subplots=true)
         
         ## if we know the correct ranges values for the date you can query to see the bad data
df.query('name == "cpu" & (value < 0 | value > 100)')

         ## using z_score to calculate bad date (data distribution)
mem = df [df['name' == "mem"] ['value']
z_score = (mem - mem.mean())/mem.std()
bad_mem = mem[z_score.abs() > 2]

        ## then we look at the "bad data"
df.loc[bad_mem.index]

--------------------------------------------------### Cleaning duplicates values
import pandas as pd

df = pd.read_csv('cart.csv', parse_dates= ['date'])
df

        ## we find duplicates considering ALL COLUMNS, boolean filter: false/true
df.duplicated()
        ## dup using specific columns
df.duplicated(['date','name'])

--------------------------------------------------### Data validation  converted from JSON/YAML (or something else) to Python data-types.

import pandas as pd
df = pd.read_csv('ships.cvs')
df

         ### Validate if we have NULLs in columns (pandas schema validate does not allows nulls columns)

import pandera as pa

schema = pa.DataFrameSchema({
  'name': pa.Column(pa.String),
  'lat': pa.Column(pa.Float, nullable=True),
  'lng': pa.Column(pa.Float, nullable=True),
})
schema.validate(df)


--------------------------------------------------### Finding missing data

import pandas as pd
df = pd.read_csv('ships.cvs')
df

         # see if we have nulls BY ROWS
df[df.isnull().any(axis=1)]

          # Detects an empty space in 'name' (tecnically not null)
df.iloc[-1]['name']  

          # if we TRIM spaces is a NULL
df['name'] = df ['name'].str.strip()
df.iloc[-1]['name']

          ### Validate missing data (pandas only recognices NaN numeric, Nan or None object, Nat in datatimelike)
          # we import numpy and set values of empty string to = NaN to recognice it
import numpy as np
mask = df ['name'].str.strip() == ''
df.loc[mask,'name'] = np.nan

          # try again to see all the real NULLs
df[df.isnull().any(axis=1)]

--------------------------------------------------### 
